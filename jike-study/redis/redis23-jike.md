#   redis23-旁路缓存，redis是如何工作的



abstract:我们来了解下缓存的特征和 Redis 适用于缓存的天然优势，以及 Redis 缓存的具体工作机制。

Redis 提供了高性能的数据存取功能，所以广泛应用在缓存场景中，有两个优点:

1. 能有效地提升业务应用的响应速度
2. 可以避免把高并发大压力的请求发送到数据库层。

但是，如果 Redis 做缓存时出现了问题，比如说缓存失效，大量请求就会直接积压到数据库层，必然会给数据库带来巨大的压力，很可能会导致数据库宕机或是故障，那么，业务应用就没有办法存取数据、响应用户请求了。正因为 Redis 用作缓存的普遍性以及它在业务应用中的重要作用，所以，我们需要系统地掌握缓存的一系列内容，包括工作原理、替换策略、异常处理和扩展机制。具体来说，我们需要解决四个关键问题：

1. Redis 缓存具体是怎么工作的？
2. Redis 缓存如果满了，该怎么办？
3. 为什么会有缓存一致性、缓存穿透、缓存雪崩、缓存击穿等异常，该如何应对？
4. Redis 的内存毕竟有限，如果用快速的固态硬盘来保存数据，可以增加缓存的数据量，那么，Redis 缓存可以使用快速固态硬盘吗？



### 缓存的特征

要想弄明白 Redis 为什么适合用作缓存，我们得清楚缓存都有什么特征。

首先需要知道，**一个系统中的不同层之间的访问速度不一样**，所以我们才需要缓存，这样就可以把一些需要频繁访问的数据放在缓存中，以加快它们的访问速度。

以计算机系统为例，下图是计算机系统中的三层存储结构，以及它们各自的常用容量和访问性能。最上面是处理器，中间是内存，最下面是磁盘。

CPU、内存和磁盘这三层的访问速度从几十 ns 到 100ns，再到几 ms，性能的差异很大。

想象一下，如果每次 CPU 处理数据时，都要从 ms 级别的慢速磁盘中读取数据，然后再进行处理，那么，CPU 只能等磁盘的数据传输完成。这样一来，高速的 CPU 就被慢速的磁盘拖累了，整个计算机系统的运行速度会变得非常慢。

所以，计算机系统中，默认有两种缓存：

1. CPU 里面的末级缓存，即 LLC，用来缓存内存中的数据，避免每次从内存中存取数据；
2. 内存中的高速页缓存，即 page cache，用来缓存磁盘中的数据，避免每次从磁盘中存取数据。

访问速度:LLC>内存>磁盘。

缓存的第一个特征：在一个层次化的系统中，缓存一定是一个快速子系统，数据存在缓存中时，能避免每次从慢速子系统中存取数据。对应到互联网应用来说，Redis 就是快速子系统，而数据库就是慢速子系统了。

我们再看一下刚才的计算机分层结构。LLC 的大小是 MB 级别，page cache 的大小是 GB 级别，而磁盘的大小是 TB 级别。

这包含了缓存的第二个特征：缓存系统的容量大小总是小于后端慢速系统的，我们不可能把所有数据都放在缓存系统中。

缓存和后端慢速系统之间，必然存在数据写回和再读取的交互过程。即缓存中的数据需要按一定规则淘汰出去，写回后端系统，而新的数据又要从后端系统中读取进来，写入缓存。

### Redis 缓存处理请求的两种情况

缓存命中：Redis 中有相应数据，就直接读取 Redis，性能非常快。

缓存缺失：Redis 中没有保存相应数据，就从后端数据库中读取数据，性能就会变慢。而且，一旦发生缓存缺失，为了让后续请求能从缓存中读取到数据，我们需要把缺失的数据写入 Redis，这个过程叫作缓存更新。缓存更新操作会涉及到保证缓存和数据库之间的数据一致性问题。

使用 Redis 缓存时，我们基本有三个操作：

1. 应用读取数据时，需要先读取 Redis；
2. 发生缓存缺失时，需要从数据库读取数据；
3. 发生缓存缺失时，还需要更新缓存。

那么，这些操作具体是由谁来做的呢？这和 Redis 缓存的使用方式相关。

### Redis 作为旁路缓存的使用操作

Redis 是一个独立的系统软件，和业务应用程序是两个软件，所以，如果应用程序想要使用 Redis 缓存，我们就要在程序中增加相应的缓存操作代码。因此我们也把 Redis 称为旁路缓存，也就是说，读取缓存、读取数据库和更新缓存的操作都需要在应用程序中来完成。

这和我刚才讲的计算机系统中的 LLC 和 page cache 不一样。你可以回想下，平时在开发程序时，我们是没有专门在代码中显式地创建 LLC 或 page cache 的实例的，也没有显式调用过它们的 GET 接口。这是因为，我们在构建计算机硬件系统时，已经把 LLC 和 page cache 放在了应用程序的数据访问路径上，应用程序访问数据时直接就能用上缓存。

那么，使用 Redis 缓存时，具体来说，我们需要在应用程序中增加三方面的代码：

1. 当应用程序需要读取数据时，我们需要在代码中显式调用 Redis 的 GET 操作接口，进行查询；
2. 如果缓存缺失了，应用程序需要再和数据库连接，从数据库中读取数据；
3. 当缓存中的数据需要更新时，我们也需要在应用程序中显式地调用 SET 操作接口，把更新的数据写入缓存。

###  缓存的类型

按照 Redis 缓存是否接受写请求，我们可以把它分成只读缓存和读写缓存。

- 只读缓存

优点:

1. 起到加速访问的效果
2. 只读缓存直接在数据库中更新数据，所有最新的数据都在数据库中，而数据库是提供数据可靠性保障的，这些数据不会有丢失的

适用场景:

​	需要缓存图片、短视频这些用户只读的数据

- 读写缓存

优点:

1.  Redis 的高性能访问特性，数据的增删改操作可以在缓存中快速完成，提升业务应用的响应速度。

缺点:

​		最新的数据是在 Redis 中，掉电或宕机会导致内存中的数据丢失，给应用业务带来风险。



### 两种策略

根据业务应用对数据可**靠性和缓存性能**的不同要求，我们会有同步直写和异步写回两种策略。

- 同步直写策略优先保证数据可靠性
- 异步写回策略优先提供快速响应

#### 同步直写:

1. 写请求同时发给缓存和后端数据库进行处理，等到两者都写完数据，才给客户端返回。
2. 保证最新的数据仍然保存在数据库中，提供了数据可靠性保证。
3. 会降低缓存的访问性能。缓存中处理写请求的速度快于数据库处理写请求的速度，需要等待数据库处理完所有的写请求，才能给应用返回结果，增加了缓存的响应延迟。

#### 异步写回策略:

1. 优先考虑了响应延迟。所有写请求都先在缓存中处理。等到这些增改的数据要被从缓存中淘汰出来时，缓存将它们写回后端数据库。
2. 处理这些数据的操作是在缓存中进行的，处理速度响应速度快。
3. 如果发生掉电且没有被写回数据库，存在丢失的风险。



关于是选择只读缓存，还是读写缓存，主要看我们**对写请求是否有加速**的需求。

如果需要对写请求进行加速，我们选择读写缓存；

如果写请求很少，或者是只需要提升读请求的响应速度的话，我们选择只读缓存。

eg:商品大促，商品的库存信息选择读写缓存的模式。短视频 App 的场景中修改并不频繁，选择只读缓存模式。

### 小结

1、学习了缓存的两个特征:

- 在分层系统中，数据暂存在快速子系统中有助于加速访问；

- 缓存容量有限，缓存写满时，数据需要被淘汰

  Redis 天然就具有高性能访问和数据淘汰机制，正好符合缓存的这两个特征的要求，所以非常适合用作缓存。

2、 Redis 作为旁路缓存的特性，旁路缓存就意味着需要在应用程序中新增缓存逻辑处理的代码。

3、Redis 做缓存时的两种模式

- 只读缓存

- 读写缓存。

  ----同步直写模式，侧重于保证数据可靠性

  ----异步写回模式，侧重于提供低延迟访问



### 每课一问

按照惯例，我给你提一个小问题。这节课，我提到了 Redis 只读缓存和使用直写策略的读写缓存，这两种缓存都会把数据同步写到后端数据库中，你觉得，它们有什么区别吗？





# redis24-替换策略，缓存满了怎么办

abstract:这节课上聊聊缓存满了之后的数据淘汰机制。通常，我们也把它叫作缓存替换机制，同时还会讲到一系列选择淘汰数据的具体策略。了解了数据淘汰机制和相应策略，我们才可以选择合理的 Redis 配置，提高缓存命中率，提升应用的访问性能。



Redis 缓存使用内存来保存数据，可以提升应用的响应速度。如果我们把所有要访问的数据都放入缓存，是不是一个很好的设计选择呢？其实，这样做的性价比反而不高。

1、因为性价比很低。1TB 内存的价格大约是 3.5 万元，而 1TB 磁盘的价格大约是 1000 元。

2、数据访问都是有局部性的，“八二原理”，80% 的请求实际只访问了 20% 的数据。用 1TB 的内存做缓存没有必要。



### 缓存数据的淘汰机制。

操作原则:

第一，根据一定的策略，筛选出对应用访问来说“不重要”的数据；

第二，将这些数据从缓存中删除，为新来的数据腾出空间，

​		系统的设计选择是一个权衡的过程：大容量缓存是能带来性能加速的收益，但是成本也会更高，而小容量缓存不一定就起不到加速访问的效果。一般建议把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销。

对于 Redis 来说，一旦确定了缓存最大容量，比如 4GB，你就可以使用下面这个命令来设定缓存的大小了：

CONFIG SET maxmemory 4gb

缓存替换需要解决两个问题：决定淘汰哪些数据，如何处理那些被淘汰的数据。

### Redis 缓存有哪些淘汰策略？

1.  noeviction----不进行数据淘汰的策略
2. volatile-random----设置了过期时间的键值对中，进行随机删除。
3. volatile-ttl----设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除
4. volatile-lru---LRU 算法筛选设置了过期时间的键值
5. volatile-lfu---- LFU 算法选择设置了过期时间的键值对
6. allkeys-lru----使用 LRU 算法在所有数据中进行筛选
7. allkeys-random---从所有键值对中随机选择并删除数据
8. allkeys-lfu----使用 LFU 算法在所有数据中进行筛选



### LRU 算法

Least Recently Used，最近最少使用的原则来筛选数据，最不常用的数据会被筛选出来，而最近频繁使用的数据会留在缓存中。

LRU 会把所有的数据组织成一个链表，链表的头和尾分别表示 MRU 端和 LRU 端，分别代表最近最常使用的数据和最近最不常用的数据。

我们现在有数据 6、3、9、20、5。如果数据 20 和 3 被先后访问，它们都会从现有的链表位置移到 MRU 端，而链表中在它们之前的数据则相应地往后移一位。因为，LRU 算法选择删除数据时，都是从 LRU 端开始，所以把刚刚被访问的数据移到 MRU 端，就可以让它们尽可能地留在缓存中。

如果有一个新数据 15 要被写入缓存，但此时已经没有缓存空间了，也就是链表没有空余位置了，那么，LRU 算法做两件事：

数据 15 是刚被访问的，所以它会被放到 MRU 端；

算法把 LRU 端的数据 5 从缓存中删除，相应的链表中就没有数据 5 的记录了。

其实，LRU 算法背后的想法非常朴素：它认为刚刚被访问的数据，肯定还会被再次访问，所以就把它放在 MRU 端；长久不访问的数据，肯定就不会再被访问了，所以就让它逐渐后移到 LRU 端，在缓存满时，就优先删除它。

不过，LRU 算法在实际实现时，需要用链表管理所有的缓存数据，这会带来额外的空间开销。而且，当有数据被访问时，需要在链表上把该数据移动到 MRU 端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。

所以，在 Redis 中，LRU 算法被做了简化，以减轻数据淘汰对缓存性能的影响。具体来说，Redis 默认会记录每个数据的最近一次访问的时间戳（由键值对数据结构 RedisObject 中的 lru 字段记录）。然后，Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。

Redis 提供了一个配置参数 maxmemory-samples，这个参数就是 Redis 选出的数据个数 N。例如，我们执行如下命令，可以让 Redis 选出 100 个数据作为候选数据集：

CONFIG SET maxmemory-samples 100

当需要再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。这儿的挑选标准是：能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值。当有新数据进入候选数据集后，如果候选数据集中的数据个数达到了 maxmemory-samples，Redis 就把候选数据集中 lru 字段值最小的数据淘汰出去。

这样一来，Redis 缓存不用为所有的数据维护一个大链表，也不用在每次数据访问时都移动链表项，提升了缓存的性能。

### 方案选择

优先使用 allkeys-lru 策略。这样，可以充分利用 LRU 这一经典缓存算法的优势，把最近最常访问的数据留在缓存中，提升应用的访问性能。如果你的业务数据中有明显的冷热数据区分，我建议你使用 allkeys-lru 策略。

如果业务应用中的数据访问频率相差不大，没有明显的冷热数据区分，建议使用 allkeys-random 策略，随机选择淘汰的数据就行。

如果你的业务中有置顶的需求，比如置顶新闻、置顶视频，那么，可以使用 volatile-lru 策略，同时不给这些置顶数据设置过期时间。这样一来，这些需要置顶的数据一直不会被删除，而其他数据会在过期时根据 LRU 规则进行筛选。



### 小结

1、“缓存满了该怎么办”，向你介绍了缓存替换时的数据淘汰策略，以及被淘汰数据的处理方法。Redis 4.0 版本以后一共提供了 8 种数据淘汰策略，从淘汰数据的候选集范围来看，我们有两种候选范围：一种是所有数据都是候选集，一种是设置了过期时间的数据是候选集。三种策略，分别是随机选择，根据 LRU 算法选择，以及根据 LFU 算法选择。

2、使用建议

- 先根据是否有始终会被频繁访问的数据（例如置顶消息），来选择淘汰数据的候选集，也就是决定是针对所有数据进行淘汰，还是针对设置了过期时间的数据进行淘汰。候选数据集范围选定后，建议优先使用 LRU 算法，也就是，allkeys-lru 或 volatile-lru 策略。

- 设置缓存容量的大小需结合实际应用的数据总量、热数据的体量，以及成本预算，把缓存空间大小设置在总数据量的 15% 到 30% 这个区间就可以。

### 每课一问

按照惯例，我给你提一个小问题。这节课，我向你介绍了 Redis 缓存在应对脏数据时，需要在数据修改的同时，也把它写回数据库，针对我们上节课介绍的缓存读写模式：只读缓存，以及读写缓存中的两种写回策略，请你思考下，Redis 缓存对应哪一种或哪几种模式？

欢迎在留言区写下你的思考和答案，我们一起交流讨论。如果你觉得今天的内容对你有所帮助，也欢迎你分享给你的朋友或 / 同事。我们下节课见。



# redis25-如何解决缓存与数据库不一致的问题

如果数据不一致，业务应用从缓存中读取的数据就不是最新数据，会导致严重的错误。比如说，我们把电商商品的库存信息缓存在 Redis 中，如果库存信息不对，那么业务层下单操作就可能出错，这当然是不能接受的。所以，这节课我们就聊聊这个问题。

### 缓存和数据库的数据不一致是如何发生的？

首先，我们得清楚“数据的一致性”具体是啥意思。其实，这里的“一致性”包含了两种情况：

1. 若缓存中有数据，则缓存的数据值需要和数据库中的值相同；

2. 若缓存中本身没有数据，则数据库中的值必须是最新值。

   对于读写缓存来说，如果要对数据进行增删改，就需要在缓存中进行，同时还要根据采取的写回策略，决定是否同步写回到数据库中。

同步直写策略：写缓存时，也同步写数据库，缓存和数据库中的数据一致；

异步写回策略：写缓存时不同步写数据库，等到数据从缓存中淘汰时，再写回数据库。使用这种策略时，如果数据还没有写回数据库，缓存就发生了故障，此时数据库就不存在最新的数据。

---- 对于**读写缓存**来说，要想保证缓存和数据库中的数据一致，就要采用同步直写策略。即:同时更新缓存和数据库。所以，我们要在业务应用中使用**事务机制**，来**保证缓存和数据库的更新具有原子性**，**两者要不一起更新，要不都不更新，返回错误信息，进行重试**。如果业务场景对数据一致性的要求不高，比如说缓存的是电商商品的非关键属性或者短视频的创建或修改时间等，就适合使用异步写回策略。

----对于**只读缓存**来说，新增数据的操作会直接写入数据库；删改数据就需要把只读缓存中的数据标记为无效。如果应用后续再访问这些增删改的数据时，会发生缓存缺失，会从数据库中把数据读入缓存，这样后续再访问数据时，就能够直接从缓存中读取了。



### 如何解决数据不一致问题？

#### 方法一:重试机制。

​		可以把要变更的数据值暂存到消息队列中（例如使用 Kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取再次进行删除或更新。如果成功就把这些值从消息队列中去除，可以保证数据库和缓存的数据一致了。否则的话，再次进行重试。如果重试超过的一定次数仍然不成功，就向业务层发送报错信息。

下图显示了先更新数据库，再删除缓存值时，如果缓存删除失败，再次重试后删除成功的情况，你可以看下。

刚刚说的是在更新数据库和删除缓存值的过程中，其中一个操作失败的情况，实际上，即使这两个操作第一次执行时都没有失败，当有大量并发请求时，应用还是有可能读到不一致的数据。

同样，我们按照不同的删除和更新顺序，分成两种情况来看。在这两种情况下，我们的解决方法也有所不同。

情况一：先删除缓存，再更新数据库。

假设线程 A 删除缓存值后，还没有来得及更新数据库（比如说有网络延迟），线程 B 就开始读取数据了，那么这个时候，线程 B 会发现缓存缺失，就只能去数据库读取。这会带来两个问题：

线程 B 读取到了旧值；

线程 B 是在缓存缺失的情况下读取的数据库，所以，它还会把旧值写入缓存，这可能会导致其他线程从缓存中读到旧值。

等到线程 B 从数据库读取完数据、更新了缓存后，线程 A 才开始更新数据库，此时，缓存中的数据是旧值，而数据库中的是最新值，两者就不一致了。

#### **方法二:延迟双删**

​		在线程 A 更新完数据库值以后，让它先 sleep 一小段时间，再进行一次缓存删除操作。加上 sleep 的这段时间是为了让线程 B 能够先从数据库读取数据，再把缺失的数据写入缓存，然后，线程 A 再进行删除。所以，线程 A sleep 的时间需要>线程 B 读取数据再写入缓存的时间。这个时间可以通过统计线程读数据和写缓存的操作时间为基础进行估算。

​		其它线程读取数据时，会由于缓存缺失去数据库中读取最新值。因为这个方案会在第一次删除缓存值后，延迟一段时间再次进行删除，所以我们也把它叫做“**延迟双删**”。

下面的这段伪代码就是“延迟双删”方案的示例，你可以看下。

```go
redis.delKey(X)
db.update(X)
Thread.sleep(N)
redis.delKey(X)
```

情况二：先更新数据库值，再删除缓存值。

如果线程 A 删除了数据库中的值，但还没来得及删除缓存值，线程 B 就开始读取数据了，那么此时，线程 B 查询缓存时，发现缓存命中，就会直接从缓存中读取旧值。不过，在这种情况下，如果其他线程并发读缓存的请求不多，那么，就不会有很多请求读取到旧值。而且，线程 A 一般也会很快删除缓存值，这样一来，其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小。

缓存和数据库的数据不一致一般是由两个原因导致的，删除缓存值或更新数据库失败，可使用重试机制确保删除或更新操作成功。

在删除缓存值、更新数据库的这两步操作中，有其他线程的并发读操作，导致其他线程读取到旧值，应对方案是延迟双删。

### 小结

1、缓存和数据库不一致的问题可以分成读写缓存和只读缓存两种情况进行分析。

- 对于读写缓存来说，如果我们采用同步写回策略，那么可以保证缓存和数据库中的数据一致。
- 只读缓存的情况总结如下，以便于你更加清晰地了解数据不一致的问题原因、现象和应对方案。

2、在大多数业务场景下，我们会把 Redis 作为只读缓存使用。针对只读缓存来说，我们既可以先删除缓存值再更新数据库，也可以先更新数据库再删除缓存。建议优先使用先更新数据库再删除缓存的方法，原因主要有两个：

- 先删除缓存值再更新数据库，有可能导致请求因缓存缺失而访问数据库，给数据库带来压力；

- 如果业务应用中读取数据库和写缓存的时间不好估算，那么，延迟双删中的等待时间就不好设置。

3、先更新数据库再删除缓存时，如果业务层要求必须读取一致的数据，需要在更新数据库时先在 Redis 缓存客户端暂存并发读请求，等数据库更新完、缓存值删除后，再读取数据，从而保证数据一致性。

### 每课一问

按照惯例，我给你提个小问题。这节课，我提到，在只读缓存中进行数据的删改操作时，需要在缓存中删除相应的缓存值。我想请你思考一下，如果在这个过程中，我们不是删除缓存值，而是直接更新缓存的值，你觉得和删除缓存值相比，有什么好处和不足吗？





# redis26-缓存异常，如何解决缓存雪崩、缓存击透的问题。

Abstarct:缓存雪崩、缓存击穿和缓存穿透这三个缓存常见问题的表现、诱发原因以及解决方法

#### 缓存雪崩

缓存雪崩是指大量的应用请求无法在 Redis 缓存中进行处理，应用将大量请求发送到数据库层，导致数据库层的压力激增。

缓存雪崩的原因

1. 第一个原因：缓存中有大量数据同时过期，导致大量请求无法得到处理。

两种解决方案:

- 可以避免给大量的数据设置相同的过期时间，如微调过期时间。如果业务层的确要求有些数据同时失效，你可以在用 EXPIRE 命令给每个数据设置过期时间时，给这些数据的过期时间增加一个较小的随机数，既避免了大量数据同时过期，同时也保证了这些数据基本在相近的时间失效，仍然能满足业务需求。

- 服务降级，针对不同的数据采取不同的处理方式。

  ----当业务应用访问的是非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；

  ----当业务应用访问的是核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。

2. 第二个原因:缓存实例发生故障宕机了，无法处理请求，导致大量请求一下子积压到数据库层，从而发生缓存雪崩。

两种解决方案:

1. 在业务系统中实现**服务熔断**或**请求限流机制**。

   ##### 服务熔断

   ##### 概念:

   通过暂停业务应用对缓存系统的接口访问,避免了大量请求因缓存缺失，而积压到数据库系统，保证了数据库系统的正常运。即:业务应用调用缓存接口时，缓存客户端并不把请求发给 Redis 缓存实例，而是直接返回，等到 Redis 缓存实例重新恢复服务后，再允许应用请求发送到缓存系统。

   ##### 优点:保证数据库的正常运行

   ##### 缺点:暂停了整个缓存系统的访问，对业务应用的影响范围大。

   ##### 请求限流。

   ##### 概念:在业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。

   假设业务系统正常运行时，请求入口前端允许每秒进入系统的请求是 1 万个，其中9000 个在缓存系统中进行处理，1000 个会到数据库进行处理。发生了缓存雪崩导致数据库的每秒请求数突然增加到每秒 1 万个，此时可以启动请求限流机制，在请求入口前端只允许每秒进入系统的请求数为 1000 个，再多的请求就会在入口前端被直接拒绝服务。所以，使用了请求限流，就可以避免大量并发请求压力传递到数据库层。

使用服务熔断或是请求限流机制对于应对 Redis 实例宕机导致的缓存雪崩问题“事后诸葛亮”，用于已经发生缓存雪崩的情形下，通过使用这两个机制降低雪崩对数据库和整个业务系统的影响。

2. 事前预防。

通过主从节点的方式构建 Redis 缓存高可靠集群。如果 Redis 缓存的主节点故障宕机了，从节点还可以切换成为主节点，继续提供缓存服务，避免了由于缓存实例宕机而导致的缓存雪崩问题。

#### 缓存击穿

概念:

​		针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，且该数据的大量请求都被发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。

原因:缓存击穿的情况，经常发生在热点数据过期失效时

解决方式:对于访问特别频繁的热点数据不设置过期时间了。

#### 缓存穿透

概念:

​		要访问的数据既不在 Redis 缓存中，也不在数据库中，缓存成了“摆设”，如果应用持续有大量请求访问数据，就会同时给缓存和数据库带来巨大压力.

原因:

1、业务层误操作：缓存中的数据和数据库中的数据被误删除了，导致缓存和数据库中都没有数据；

2、恶意攻击：专门访问数据库中没有的数据。

三种应对方案:

- 缓存空值或缺省值。

  ​		对发生缓存穿透查询的数据，在 Redis 中缓存一个空值或是和业务层协商确定的缺省值（例如，库存的缺省值可以设为 0）。应用发送的后续请求再进行查询时，可直接从 Redis 中读取空值或缺省值返回给业务应用了

- 使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。

  ​	布隆过滤器由一个初值都为 0 的 bit 数组和 N 个哈希函数组成，可以用来快速判断某个数据是否存在。当我们想标记某个数据存在时（例如，数据已被写入数据库），布隆过滤器会通过三个操作完成标记：

首先，使用 N 个哈希函数，分别计算这个数据的哈希值，得到 N 个哈希值。

然后，我们把这 N 个哈希值对 bit 数组的长度取模，得到每个哈希值在数组中的对应位置。

最后，我们把对应位置的 bit 位设置为 1，这就完成了在布隆过滤器中标记数据的操作。

如果数据不存在（例如，数据库里没有写入数据），我们也就没有用布隆过滤器标记过数据，那么，bit 数组对应 bit 位的值仍然为 0。

当需要查询某个数据时，我们就执行刚刚说的计算过程，先得到这个数据在 bit 数组中对应的 N 个位置。紧接着，我们查看 bit 数组中这 N 个位置上的 bit 值。只要这 N 个 bit 值有一个不为 1，这就表明布隆过滤器没有对该数据做过标记，所以，查询的数据一定没有在数据库中保存。为了便于你理解，我画了一张图，你可以看下。

图中布隆过滤器是一个包含 10 个 bit 位的数组，使用了 3 个哈希函数，当在布隆过滤器中标记数据 X 时，X 会被计算 3 次哈希值，并对 10 取模，取模结果分别是 1、3、7。所以，bit 数组的第 1、3、7 位被设置为 1。当应用想要查询 X 时，只要查看数组的第 1、3、7 位是否为 1，只要有一个为 0，那么，X 就肯定不在数据库中。

正是基于布隆过滤器的快速检测特性，我们可以在把数据写入数据库时，使用布隆过滤器做个标记。当缓存缺失后，应用查询数据库时，可以通过查询布隆过滤器快速判断数据是否存在。如果不存在，就不用再去数据库中查询了。这样一来，即使发生缓存穿透了，大量请求只会查询 Redis 和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。布隆过滤器可以使用 Redis 实现，本身就能承担较大的并发访问压力。

- 在请求入口的前端进行请求检测。对业务系统接收到的请求进行合法性检测，把恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库。

#### 小结

1、问题成因:缓存雪崩和击穿主要是因为数据不在缓存中了，而缓存穿透则是因为数据既不在缓存中，也不在数据库中。所以，缓存雪崩或击穿时，一旦数据库中的数据被再次写入到缓存后，应用又可以在缓存中快速访问数据了，数据库的压力也会相应地降低下来，而缓存穿透发生时，Redis 缓存和数据库会同时持续承受请求压力。

2、服务熔断、服务降级、请求限流这些方法都是属于“有损”方案，在保证数据库和整体系统稳定的同时，会对业务应用带来负面影响。例如使用服务降级时，有部分数据的请求就只能得到错误返回信息，无法正常处理。如果使用了服务熔断，那么，整个缓存系统的服务都被暂停了，影响的业务范围更大。而使用了请求限流机制后，整个业务系统的吞吐率会降低，能并发处理的用户请求会减少，会影响到用户体验。

3、尽量使用预防式方案：

针对缓存雪崩，合理地设置数据过期时间，以及搭建高可靠缓存集群；

针对缓存击穿，在缓存访问非常频繁的热点数据时，不要设置过期时间；

针对缓存穿透，提前在入口前端实现恶意请求检测，或者规范数据库的数据删除操作，避免误删除。

#### 每课一问

按照惯例，我给你提个小问题。在讲到缓存雪崩时，我提到，可以采用服务熔断、服务降级、请求限流的方法来应对。请你思考下，这三个机制可以用来应对缓存穿透问题吗？

# redis27-缓存被污染了怎么办

​		什么是缓存污染呢？在一些场景下，有些数据被访问的次数非常少，当这些数据服务完访问请求后，如果还继续留存在缓存中的话，就只会白白占用缓存空间。这种情况，就是缓存污染。

#### 如何解决缓存污染问题？

缓存的淘汰策略

#### LRU 缓存策略

核心思想：如果一个数据刚刚被访问，那么这个数据肯定是热数据，还会被再次访问。

​		Redis 中的 LRU 策略，会在每个数据对应的 RedisObject 结构体中设置一个 lru 字段，用来记录数据的访问时间戳。在进行数据淘汰时，LRU 策略会在候选数据集中淘汰掉 lru 字段值最小的数据（也就是访问时间最久的数据）。

​		在数据被频繁访问的业务场景中，LRU 策略的确能有效留存访问时间最近的数据。而且，因为留存的这些数据还会被再次访问，所以又可以提升业务应用的访问速度。

​		使用 LRU 策略在处理扫描式单次查询操作时，无法解决缓存污染。扫描式单次查询操作是应用对大量的数据进行一次全体读取，每个数据都会被读取，而且只会被读取一次。此时，因为这些被查询的数据刚刚被访问过，所以 lru 字段值都很大。在使用 LRU 策略淘汰数据时，这些数据会留存在缓存中很长一段时间，造成缓存污染。如果查询的数据量很大，这些数据占满了缓存空间，却又不会服务新的缓存请求，此时，再有新数据要写入缓存的话，还是需要先把这些旧数据替换出缓存才行，这会影响缓存的性能。

#### LFU 缓存策略

LFU 策略中会从两个维度来筛选并淘汰数据：一是，数据访问的时效性（访问时间离当前时间的远近）；二是，数据的被访问次数。

LFU 缓存策略的优化

LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。

和那些被频繁访问的数据相比，扫描式单次查询的数据因为不会被再次访问，所以它们的访问次数不会再增加。因此，LFU 策略会优先把这些访问次数低的数据淘汰出缓存。这样一来，LFU 策略就可以避免这些数据对缓存造成污染了。、

#### 实现

为了避免操作链表的开销，Redis 在实现 LRU 策略时使用了两个近似方法：

那么，LFU 策略具体又是如何实现的呢？既然 LFU 策略是在 LRU 策略上做的优化，那它们的实现必定有些关系。所以，我们就再复习下第 24 讲学习过的 LRU 策略的实现。

为了避免操作链表的开销，Redis 在实现 LRU 策略时使用了两个近似方法：

Redis 是用 RedisObject 结构来保存数据的，RedisObject 结构中设置了一个 lru 字段，用来记录数据的访问时间戳；

Redis 并没有为所有的数据维护一个全局的链表，而是通过随机采样方式，选取一定数量（例如 10 个）的数据放入候选集合，后续在候选集合中根据 lru 字段值的大小进行筛选。

在此基础上，Redis 在实现 LFU 策略的时候，只是把原来 24bit 大小的 lru 字段，又进一步拆分成了两部分。

ldt 值：lru 字段的前 16bit，表示数据的访问时间戳；

counter 值：lru 字段的后 8bit，表示数据的访问次数。

总结一下：当 LFU 策略筛选数据时，Redis 会在候选集合中，根据数据 lru 字段的后 8bit 选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据 lru 字段的前 16bit 值大小，选择访问时间最久远的数据进行淘汰。

到这里，还没结束，Redis 只使用了 8bit 记录数据的访问次数，而 8bit 记录的最大值是 255，这样可以吗？

在实际应用中，一个数据可能会被访问成千上万次。如果每被访问一次，counter 值就加 1 的话，那么，只要访问次数超过了 255，数据的 counter 值就一样了。在进行数据淘汰时，LFU 策略就无法很好地区分并筛选这些数据，反而还可能会把不怎么访问的数据留存在了缓存中。

我们一起来看个例子。

假设第一个数据 A 的累计访问次数是 256，访问时间戳是 202010010909，所以它的 counter 值为 255，而第二个数据 B 的累计访问次数是 1024，访问时间戳是 202010010810。如果 counter 值只能记录到 255，那么数据 B 的 counter 值也是 255。

此时，缓存写满了，Redis 使用 LFU 策略进行淘汰。数据 A 和 B 的 counter 值都是 255，LFU 策略再比较 A 和 B 的访问时间戳，发现数据 B 的上一次访问时间早于 A，就会把 B 淘汰掉。但其实数据 B 的访问次数远大于数据 A，很可能会被再次访问。这样一来，使用 LFU 策略来淘汰数据就不合适了。

的确，Redis 也注意到了这个问题。因此，在实现 LFU 策略时，Redis 并没有采用数据每被访问一次，就给对应的 counter 值加 1 的计数规则，而是采用了一个更优化的计数规则。

简单来说，LFU 策略实现的计数规则是：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。

下面这段 Redis 的部分源码，显示了 LFU 策略增加计数器值的计算逻辑。其中，baseval 是计数器当前的值。计数器的初始值默认是 5（由代码中的 LFU_INIT_VAL 常量设置），而不是 0，这样可以避免数据刚被写入缓存，就因为访问次数少而被立即淘汰。



使用了这种计算规则后，我们可以通过设置不同的 lfu_log_factor 配置项，来控制计数器值增加的速度，避免 counter 值很快就到 255 了。

为了更进一步说明 LFU 策略计数器递增的效果，你可以看下下面这张表。这是 Redis官网上提供的一张表，它记录了当 lfu_log_factor 取不同值时，在不同的实际访问次数情况下，计数器的值是如何变化的。

可以看到，当 lfu_log_factor 取值为 1 时，实际访问次数为 100K 后，counter 值就达到 255 了，无法再区分实际访问次数更多的数据了。而当 lfu_log_factor 取值为 100 时，当实际访问次数为 10M 时，counter 值才达到 255，此时，实际访问次数小于 10M 的不同数据都可以通过 counter 值区分出来。

正是因为使用了非线性递增的计数器方法，即使缓存数据的访问次数成千上万，LFU 策略也可以有效地区分不同的访问次数，从而进行合理的数据筛选。从刚才的表中，我们可以看到，当 lfu_log_factor 取值为 10 时，百、千、十万级别的访问次数对应的 counter 值已经有明显的区分了，所以，我们在应用 LFU 策略时，一般可以将 lfu_log_factor 取值为 10。

前面我们也提到了，应用负载的情况是很复杂的。在一些场景下，有些数据在短时间内被大量访问后就不会再被访问了。那么再按照访问次数来筛选的话，这些数据会被留存在缓存中，但不会提升缓存命中率。为此，Redis 在实现 LFU 策略时，还设计了一个 counter 值的衰减机制。

简单来说，LFU 策略使用衰减因子配置项 lfu_decay_time 来控制访问次数的衰减。LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。

简单举个例子，假设 lfu_decay_time 取值为 1，如果数据在 N 分钟内没有被访问，那么它的访问次数就要减 N。如果 lfu_decay_time 取值更大，那么相应的衰减值会变小，衰减效果也会减弱。所以，如果业务应用中有短时高频访问的数据的话，建议把 lfu_decay_time 值设置为 1，这样一来，LFU 策略在它们不再被访问后，会较快地衰减它们的访问次数，尽早把它们从缓存中淘汰出去，避免缓存污染。

小结

1、缓存污染问题指的是留存在缓存中的数据，实际不会被再次访问了，但是又占据了缓存空间。如果这样的数据体量很大，还需要把这些数据逐步淘汰出缓存，就会增加缓存操作的时间开销。要解决缓存污染问题，最关键的技术点就是能识别出这些只访问一次或是访问次数很少的数据，在淘汰数据时，优先把它们筛选出来并淘汰掉。

2、volatile-random 和 allkeys-random 是随机选择数据进行淘汰，无法把不再访问的数据筛选出来，可能会造成缓存污染。如果业务层明确知道数据的访问时长，可以给数据设置合理的过期时间，再设置 Redis 缓存使用 volatile-ttl 策略。当缓存写满时，剩余存活时间最短的数据就会被淘汰出缓存，避免滞留在缓存中，造成污染。

3、当我们使用 LRU 策略时，由于 LRU 策略只考虑数据的访问时效，对于只访问一次的数据来说，LRU 策略无法很快将其筛选出来。而 LFU 策略在 LRU 策略基础上进行了优化，在筛选数据时，首先会筛选并淘汰访问次数少的数据，然后针对访问次数相同的数据，再筛选并淘汰访问时间最久远的数据。

在具体实现上，相对于 LRU 策略，Redis 只是把原来 24bit 大小的 lru 字段，又进一步拆分成了 16bit 的 ldt 和 8bit 的 counter，分别用来表示数据的访问时间戳和访问次数。为了避开 8bit 最大只能记录 255 的限制，LFU 策略设计使用非线性增长的计数器来表示数据的访问次数。

LRU 和 LFU 两个策略关注的数据访问特征各有侧重，LRU 策略更加关注**数据的时效性**，而 LFU 策略更加关注**数据的访问频次**。

此外，如果业务应用中有短时高频访问的数据，除了 LFU 策略本身会对数据的访问次数进行自动衰减以外，我再给你个小建议：你可以优先使用 volatile-lfu 策略，并根据这些数据的访问时限设置它们的过期时间，以免它们留存在缓存中造成污染。



#### 每课一问

按照惯例，我给你提个小问题。使用了 LFU 策略后，你觉得缓存还会被污染吗？