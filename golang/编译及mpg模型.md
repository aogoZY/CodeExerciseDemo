> 背景：一个golang程序，从编译到运行，发生了什么？这篇文章是我在看go的mpg模型的时候找到的，神奇的是我找不到其他的类似文章作为补充，那这个作者是第一个去分析这些go的编译、go的运行过程中发生了什么，以我现在的认知看这些东西，我觉得蛮有意思蛮广的，希望以后在多接触一些底层的知识后再来补充。

## **一. 为什么要先编译**

### 1. 计算机怎么运算的？

​		众所周知，计算机只能认出0和1，why？？，因为计算机是用电的，电路里只有一个真理，那就是1通电和0不通电，这就可以通过1和0来实现运算器！为了方便操作后面诞生了机器指令和汇编，既然这样，那我们的计算机语言是不是都要转为机器指令才能让计算机运行，**所以我们需要将golang编译一下生成一个二进制文件，里面包含了机器码**。

### 2. 编译期间做了什么？

​		　go build过程中，到底发生了什么？编译过程就是对源文件进行词法分析、语法分析、语义分析、优化，最后生成汇编代码文件，以 `.s` 作为文件后缀。之后，汇编器会将汇编代码转变成机器可以执行的指令。

![img](https://img2020.cnblogs.com/blog/1006642/202003/1006642-20200324154842455-215774691.png)

### 3. 编译期间分配内存？（**go**在编译的时候进行逃逸分析，来决定一个对象放栈上还是放堆上）

1）`栈是在编译期间分配内存，堆是在运行期间分配内存`。这是网上甚至教科书经常出现的说法。我刚开始很纳闷，为什么你这程序都还没跑就分配内存啦？其实正确的理解应该是：栈内存不是由编译器分配，而是由编译器确定，并且记录生成到机器码里面，而堆在编译期间是无法确定大小。所以，最终生成二进制可执行文件，这东东当然是存在磁盘里面，怎么会占用你的运行内存。

其实当你打开执行了该文件，程序会加载到内存里面，调用函数的时候会拉出一块连续的栈空间，执行完函数后回收，整个过程都是由os来操作，堆就不同了，需要写代码时就想好在运行的时候如何动态分配和回收内存。（所以为什么大部分程序崩溃都是运行时出错）。后面我们讲的golang内存分配主要是发生在堆里！！！

　　　**二. 双击一个golang程序发生了什么**

　　1. 操作系统做了什么？

　　　　1）首先来科普一下os，os是在cpu之后出现的，那是因为硬件出现了，软件也要跟上时代，要不，谁去管理这些复杂的硬件设施呢。

　　　　2）我们都知道cpu是由运算器，控制器和cache三大部分组成，cache就是寄存器，也可以理解成存储器。

　　　　3）CPU从存储器或高速缓冲存储器中取出指令，放入指令寄存器，并对指令译码。它把指令分解成一系列的微操作，然后发出各种控制命令，执行微操作系列，从而完成一条指令的执行。

　　　　很多人说内存最快，那只是相对于磁盘来说很快，比起寄存器还是差一个级别，寄存器在cpu里（距离最近当然快啦^^）。对不起，跑偏了，下面说说内存吧

　　2. 操作系统怎么分配内存？

　　　　1）每一个内存单元是不是都要有个标志，这样才能找到它？是的，这时候地址总线作用就出来了，在存储器里以字节为单位存储信息，为正确地存放或取得信息，每一个字节单元给

　　　　予一个唯一的存储器地址，称为**物理地址。**32位操作系统最大内存就是2的32次方=4GByte，地址总共4GB个，即可以寻址的空间。

　　　　2）32位操作系统只有4G空间，那么如果我同时启动几个golang程序岂不是乱套了，大家都直接寻址这4G空间，危险而且效率也很低。这时候虚拟内存就出现了，当启动程序的时候分配的

　　　　是虚拟地址，操作系统之上的程序根本就不可能接触物理地址，而且可用的物理地址是相当混乱的，必须由操作系统整理映射。

　　　　3）虚拟地址的0-3G对于一个进程的用户态和内核态来说是可以访问的，而3-4G是只有进程的内核态可以访问的

　　3. 操作系统加载内存

　　　　打开程序例如QQ **-->** CPU将需要的QQ数据从硬盘里拷贝到内存里 **-->** CPU针对内存里的QQ运算

　　　　有两个重点：

　　　　1）数据从磁盘拷贝到内存：cpu根据虚拟地址映射到物理地址的页表去寻找数据，假如没有，就会引发缺页异常，数据从磁盘拷贝到内存

　　　　2）cpu处理加载后的内存数据：因为如果cpu直接操作磁盘会造成落差很大，cpu速度很快，磁盘很慢，效率非常低，所以为什么会有那么多1级2级3级缓存。



## 二、并发(concurrency)和并行(parallellism)

**并发(concurrency)**：两个或两个以上的任务在一段时间内被执行。我们不必care这些任务在某一个时间点是否是同时执行，可能同时执行，也可能不是，我们只关心在一段时间内，哪怕是很短的时间（一秒或者两秒）是否执行解决了两个或两个以上任务。

**并行(parallellism)：**两个或两个以上的任务在同一时刻被同时执行。

并发说的是逻辑上的概念，而并行，强调的是物理运行状态。并发“包含”并行。

### Go的CSP并发模型

Go实现了两种并发形式。第一种是大家普遍认知的：多线程共享内存。其实就是Java或者C++等语言中的多线程开发。另外一种是Go语言特有的，也是Go语言推荐的：CSP（communicating sequential processes）并发模型。

CSP并发模型是在1970年左右提出的概念，属于比较新的概念，不同于传统的多线程通过共享内存来通信，CSP讲究的是“以通信的方式来共享内存”。

请记住下面这句话：
**Do not communicate by sharing memory; instead, share memory by communicating.**
“不要以共享内存的方式来通信，相反，要通过通信来共享内存。”

普通的线程并发模型，就是像Java、C++、或者Python，他们线程间通信都是通过共享内存的方式来进行的。非常典型的方式就是，在访问共享数据（例如数组、Map、或者某个结构体或对象）的时候，通过锁来访问，因此，在很多时候，衍生出一种方便操作的数据结构，叫做“线程安全的数据结构”。例如Java提供的包”java.util.concurrent”中的数据结构。Go中也实现了传统的线程并发模型。

Go的CSP并发模型，是通过`goroutine`和`channel`来实现的。

- `goroutine` 是Go语言中并发的执行单位。有点抽象，其实就是和传统概念上的”线程“类似，可以理解为”线程“。
- `channel`是Go语言中各个并发结构体(`goroutine`)之前的通信机制。 通俗的讲，就是各个`goroutine`之间通信的”管道“，有点类似于Linux中的管道。

生成一个`goroutine`的方式非常的简单：Go一下，就生成了。

### Go并发模型的实现原理

我们先从线程讲起，无论语言层面何种并发模型，到了操作系统层面，一定是以线程的形态存在的。而操作系统根据资源访问权限的不同，体系架构可分为用户空间和内核空间；内核空间主要操作访问CPU资源、I/O资源、内存资源等硬件资源，为上层应用程序提供最基本的基础资源，用户空间呢就是上层应用程序的固定活动空间，用户空间不可以直接访问资源，必须通过“系统调用”、“库函数”或“Shell脚本”来调用内核空间提供的资源。

我们现在的计算机语言，可以狭义的认为是一种“软件”，它们中所谓的“线程”，往往是用户态的线程，和操作系统本身内核态的线程（简称KSE），还是有区别的。

线程模型的实现，可以分为以下几种方式：

### Go线程实现模型MPG

`M`指的是`Machine`，代表一个内核线程，也可以称为一个工作线程。
`P`指的是`processor`，代表了`M`所需的上下文环境，也是处理用户级代码逻辑的处理器，维护了一个可运行的goroutine队列。可以把它看做一个局部的调度器。
`G`指的是`Goroutine`，其实本质上也是一种轻量级的线程，代表着goroutine 实际的数据结构(就是你封装的那个方法)，并维护者goroutine 需要的栈、程序计数器以及它所在的M等信息

三者关系如下图所示：

![](https://i6448038.github.io/img/csp/GMPrelation.png)

以上这个图讲的是两个线程(内核线程)的情况。一个M会对应一个内核线程，一个M也会连接一个上下文P，一个上下文P相当于一个“处理器”，一个上下文连接一个或者多个Goroutine。P(Processor)的数量是在启动时被设置为环境变量GOMAXPROCS的值，或者通过运行时调用函数`runtime.GOMAXPROCS()`进行设置。Processor数量固定意味着任意时刻只有固定数量的线程在运行go代码。Goroutine中就是我们要执行并发的代码。图中P正在执行的`Goroutine`为蓝色的；处于待执行状态的`Goroutine`为灰色的，灰色的`Goroutine`形成了一个队列`runqueues`

三者关系的宏观的图为：

![img](https://i6448038.github.io/img/csp/total.png)

#### 抛弃P(Processor)

你可能会想，为什么一定需要一个上下文，我们能不能直接除去上下文，让`Goroutine`的`runqueues`挂到M上呢？答案是不行，需要上下文的目的，是让我们可以直接放开其他线程，当遇到内核线程阻塞的时候。

![img](https://i6448038.github.io/img/csp/giveupP.png)

如上图左图所示，M0中的G0执行了syscall，然后就创建了一个M1(也有可能本身就存在，没创建)，（转向右图）然后M0丢弃了P，等待syscall的返回值，M1接受了P，将·继续执行`Goroutine`队列中的其他`Goroutine`。

当系统调用syscall结束后，M0会“偷”一个上下文，如果不成功，M0就把它的Gouroutine G0放到一个全局的runqueue中，然后自己放到线程池或者转入休眠状态。全局runqueue是各个P在运行完自己的本地的Goroutine runqueue后用来拉取新goroutine的地方。P也会周期性的检查这个全局runqueue上的goroutine，否则，全局runqueue上的goroutines可能得不到执行而饿死。

#### 均衡的分配工作

按照以上的说法，上下文P会定期的检查全局的goroutine 队列中的goroutine，以便自己在消费掉自身Goroutine队列的时候有事可做。假如全局goroutine队列中的goroutine也没了呢？就从其他运行的中的P的runqueue里偷。

每个P中的`Goroutine`不同导致他们运行的效率和时间也不同，在一个有很多P和M的环境中，不能让一个P跑完自身的`Goroutine`就没事可做了，因为或许其他的P有很长的`goroutine`队列要跑，得需要均衡。
该如何解决呢？

Go的做法倒也直接，从其他P中偷一半！

![img](https://i6448038.github.io/img/csp/stealwork.png)









参考文献：

[mpg模型](https://studygolang.com/articles/11825)

[golang内存分配](https://www.cnblogs.com/huangliang-hb/p/12559565.html)